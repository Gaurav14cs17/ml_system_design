<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 800 380">
  <defs>
    <linearGradient id="bgGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#0f172a"/>
      <stop offset="100%" style="stop-color:#1e293b"/>
    </linearGradient>
    <linearGradient id="cnnGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#ef4444"/>
      <stop offset="100%" style="stop-color:#f97316"/>
    </linearGradient>
    <linearGradient id="vitGrad" x1="0%" y1="0%" x2="100%" y2="100%">
      <stop offset="0%" style="stop-color:#3b82f6"/>
      <stop offset="100%" style="stop-color:#60a5fa"/>
    </linearGradient>
    <filter id="shadow" x="-10%" y="-10%" width="120%" height="130%">
      <feDropShadow dx="0" dy="4" stdDeviation="5" flood-opacity="0.25"/>
    </filter>
  </defs>
  
  <rect width="100%" height="100%" fill="url(#bgGrad)"/>
  
  <text x="400" y="40" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="22" font-weight="bold" fill="#f8fafc">⚖️ CNN vs Vision Transformer</text>
  
  <!-- CNN -->
  <g filter="url(#shadow)" transform="translate(50, 70)">
    <rect width="320" height="280" rx="16" fill="#1e293b" stroke="url(#cnnGrad)" stroke-width="3"/>
    <rect width="320" height="45" rx="16 16 0 0" fill="url(#cnnGrad)"/>
    <text x="160" y="30" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="15" font-weight="bold" fill="#fff">CNN (ResNet, EfficientNet)</text>
    
    <rect x="20" y="60" width="280" height="65" rx="8" fill="#0f172a"/>
    <text x="160" y="80" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="11" font-weight="600" fill="#f97316">How it works</text>
    <text x="160" y="98" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Local receptive fields (convolutions)</text>
    <text x="160" y="113" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Hierarchical feature extraction</text>
    
    <rect x="20" y="135" width="280" height="55" rx="8" fill="#0f172a"/>
    <text x="160" y="155" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="11" font-weight="600" fill="#4ade80">✓ Strengths</text>
    <text x="160" y="173" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Inductive bias for images</text>
    <text x="160" y="188" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Works with small datasets</text>
    
    <rect x="20" y="200" width="280" height="55" rx="8" fill="#0f172a"/>
    <text x="160" y="220" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="11" font-weight="600" fill="#f87171">✗ Weaknesses</text>
    <text x="160" y="238" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Limited global context</text>
    <text x="160" y="253" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Fixed receptive field growth</text>
  </g>
  
  <!-- ViT -->
  <g filter="url(#shadow)" transform="translate(430, 70)">
    <rect width="320" height="280" rx="16" fill="#1e293b" stroke="url(#vitGrad)" stroke-width="3"/>
    <rect width="320" height="45" rx="16 16 0 0" fill="url(#vitGrad)"/>
    <text x="160" y="30" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="15" font-weight="bold" fill="#fff">Vision Transformer (ViT)</text>
    
    <rect x="20" y="60" width="280" height="65" rx="8" fill="#0f172a"/>
    <text x="160" y="80" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="11" font-weight="600" fill="#60a5fa">How it works</text>
    <text x="160" y="98" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Global self-attention</text>
    <text x="160" y="113" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Image patches as tokens</text>
    
    <rect x="20" y="135" width="280" height="55" rx="8" fill="#0f172a"/>
    <text x="160" y="155" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="11" font-weight="600" fill="#4ade80">✓ Strengths</text>
    <text x="160" y="173" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Global context from layer 1</text>
    <text x="160" y="188" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Scales better with data</text>
    
    <rect x="20" y="200" width="280" height="55" rx="8" fill="#0f172a"/>
    <text x="160" y="220" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="11" font-weight="600" fill="#f87171">✗ Weaknesses</text>
    <text x="160" y="238" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Needs lots of training data</text>
    <text x="160" y="253" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#94a3b8">Quadratic attention cost</text>
  </g>
  
  <!-- Bottom recommendation -->
  <rect x="150" y="360" width="500" height="20" rx="4" fill="#1e293b"/>
  <text x="400" y="374" text-anchor="middle" font-family="Segoe UI, sans-serif" font-size="10" fill="#64748b">ViT wins at scale • CNN better for limited data • Hybrid models combine both</text>
</svg>
